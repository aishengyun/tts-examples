# Emotion TTS Examples

[中文](README.md)  [English](README-en.md)

Aishengyun offers powerful API interfaces to help developers build natural, responsive, real-time multimodal AI interactive experiences.

The Aishengyun API currently provides our most advanced multilingual text-to-speech model, Emotion-TTS. It can transform text into smooth, natural speech in real time, delivering lifelike and precise voice generation solutions. Effortlessly convert text into professional-grade audio that not only perfectly replicates the acoustic features of the target voice but also retains rich emotional expression and intonation. We also support creating custom AI voices from scratch, meeting your personalized needs and enabling your applications to achieve incredibly realistic voice effects, ideal for real-time and conversational experiences.

## Features
*  __Real-Time Speech Generation__
Provides efficient streaming APIs and WebSocket interfaces for millisecond-level latency in speech generation.
*  __Multilingual Support__
Supports multiple languages, including Chinese, English, and Japanese, making it easy to build global applications.
*  __Emotion Control__
Allows tone, rhythm, and emotion adjustments through voice cloning to create natural sounds for various scenarios.
*  __High Concurrency Performance__
Optimized for large-scale user concurrency with a computation cluster design, ensuring stable and reliable performance.
*  __Seamless Scalability__
Offers flexible customization capabilities, supporting training and deployment of custom voice models.

## Examples

* [Python](python/README.md) examples
* [Node.js](nodejs/README.md) examples
* [Web](web/README.md) examples

## Discussions and Community

Visit our website at [https://www.aishengyun.cn](https://www.aishengyun.cn) and join our support community.